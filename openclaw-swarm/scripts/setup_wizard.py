#!/usr/bin/env python3
"""
Agent Swarm é…ç½®å‘å¯¼
ç”¨äºæ£€æµ‹å½“å‰ OpenClaw é…ç½®çš„æ¨¡å‹ï¼Œå¹¶å¸®åŠ©ç”¨æˆ·é…ç½®æ™ºèƒ½ä½“å›¢é˜Ÿ
"""

import json
import os
import sys
from pathlib import Path

# OpenClaw é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_PATHS = [
    Path.home() / ".openclaw" / "openclaw.json",
    Path("/root/.openclaw/openclaw.json"),
]

# æ™ºèƒ½ä½“è§’è‰²å®šä¹‰
AGENT_ROLES = {
    "pm": {"name": "äº§å“ç»ç†", "emoji": "ğŸ“‹", "tier": "mid", "desc": "éœ€æ±‚åˆ†æã€ä»»åŠ¡æ‹†è§£"},
    "researcher": {"name": "ç ”ç©¶å‘˜", "emoji": "ğŸ”", "tier": "low", "desc": "ä¿¡æ¯æœé›†ã€èµ„æ–™æ•´ç†"},
    "coder": {"name": "ç¨‹åºå‘˜", "emoji": "ğŸ‘¨â€ğŸ’»", "tier": "high", "desc": "ç¼–ç ã€è°ƒè¯•ã€æµ‹è¯•"},
    "writer": {"name": "å†™ä½œè€…", "emoji": "âœï¸", "tier": "high", "desc": "æ–‡æ¡£ã€æŠ¥å‘Šã€æ–‡æ¡ˆ"},
    "designer": {"name": "è®¾è®¡å¸ˆ", "emoji": "ğŸ¨", "tier": "mid", "desc": "é…å›¾ã€æ’ç”»ï¼ˆéœ€å›¾åƒæ¨¡å‹ï¼‰"},
    "analyst": {"name": "åˆ†æå¸ˆ", "emoji": "ğŸ“Š", "tier": "high", "desc": "æ•°æ®å¤„ç†ã€ç»Ÿè®¡åˆ†æ"},
    "reviewer": {"name": "å®¡æ ¸å‘˜", "emoji": "ğŸ”", "tier": "high", "desc": "ä»£ç å®¡æŸ¥ã€å†…å®¹å®¡æ ¸"},
    "assistant": {"name": "åŠ©æ‰‹", "emoji": "ğŸ’¬", "tier": "low", "desc": "ç®€å•é—®ç­”ã€æ¶ˆæ¯è½¬å‘"},
    "automator": {"name": "è‡ªåŠ¨åŒ–", "emoji": "ğŸ¤–", "tier": "high", "desc": "å®šæ—¶ä»»åŠ¡ã€ç½‘é¡µè‡ªåŠ¨åŒ–"},
    "github-tracker": {"name": "GitHubè¿½è¸ª", "emoji": "ğŸ”¥", "tier": "low", "desc": "çƒ­é—¨é¡¹ç›®è¿½è¸ª"},
}

# ä¸»æµæ¨¡å‹æ¨èé…ç½®
RECOMMENDED_MODELS = {
    "claude-opus-4": {
        "name": "Claude Opus 4 / 4.5",
        "provider": "anthropic",
        "tier": "high",
        "desc": "æœ€å¼ºç»¼åˆèƒ½åŠ›ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡",
        "api": "anthropic-messages",
        "example_config": {
            "baseUrl": "https://api.anthropic.com/v1",
            "api": "anthropic-messages",
            "authHeader": "x-api-key"
        }
    },
    "claude-sonnet-4": {
        "name": "Claude Sonnet 4",
        "provider": "anthropic",
        "tier": "mid",
        "desc": "æ€§ä»·æ¯”é«˜ï¼Œé€‚åˆä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡",
        "api": "anthropic-messages",
        "example_config": {
            "baseUrl": "https://api.anthropic.com/v1",
            "api": "anthropic-messages",
            "authHeader": "x-api-key"
        }
    },
    "gemini-2.5-pro": {
        "name": "Gemini 2.5 Pro",
        "provider": "google",
        "tier": "mid",
        "desc": "é•¿ä¸Šä¸‹æ–‡ï¼Œé€‚åˆæ–‡æ¡£å¤„ç†",
        "api": "google-generative-ai",
        "example_config": {
            "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
            "api": "google-generative-ai",
            "authHeader": "x-goog-api-key"
        }
    },
    "gpt-4o": {
        "name": "GPT-4o",
        "provider": "openai",
        "tier": "high",
        "desc": "OpenAI æ——èˆ°æ¨¡å‹",
        "api": "openai-completions",
        "example_config": {
            "baseUrl": "https://api.openai.com/v1",
            "api": "openai-completions",
            "authHeader": "Authorization"
        }
    },
    "deepseek-v3": {
        "name": "DeepSeek V3",
        "provider": "deepseek",
        "tier": "mid",
        "desc": "é«˜æ€§ä»·æ¯”ï¼Œä¸­æ–‡ä¼˜ç§€",
        "api": "openai-completions",
        "example_config": {
            "baseUrl": "https://api.deepseek.com/v1",
            "api": "openai-completions",
            "authHeader": "Authorization"
        }
    },
    "qwen-max": {
        "name": "Qwen Max",
        "provider": "alibaba",
        "tier": "mid",
        "desc": "é˜¿é‡Œäº‘é€šä¹‰åƒé—®ï¼Œä¸­æ–‡å¼º",
        "api": "openai-completions",
        "example_config": {
            "baseUrl": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api": "openai-completions",
            "authHeader": "Authorization"
        }
    },
    "glm-4": {
        "name": "GLM-4",
        "provider": "zhipu",
        "tier": "low",
        "desc": "æ™ºè°±æ¸…è¨€ï¼Œæˆæœ¬ä½",
        "api": "openai-completions",
        "example_config": {
            "baseUrl": "https://open.bigmodel.cn/api/paas/v4",
            "api": "openai-completions",
            "authHeader": "Authorization"
        }
    }
}


def load_openclaw_config():
    """åŠ è½½ OpenClaw é…ç½®æ–‡ä»¶"""
    for config_path in CONFIG_PATHS:
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f), config_path
    return None, None


def get_available_models(config):
    """ä»é…ç½®ä¸­æå–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    models = []
    if not config or 'models' not in config:
        return models
    
    providers = config.get('models', {}).get('providers', {})
    for provider_id, provider_config in providers.items():
        for model in provider_config.get('models', []):
            model_id = model.get('id', '')
            model_name = model.get('name', model_id)
            full_id = f"{provider_id}/{model_id}"
            
            # åˆ¤æ–­æ¨¡å‹èƒ½åŠ›ç­‰çº§
            tier = "mid"
            model_lower = model_id.lower()
            if any(x in model_lower for x in ['opus', 'gpt-4', 'pro']):
                tier = "high"
            elif any(x in model_lower for x in ['glm', 'flash', 'mini']):
                tier = "low"
            
            # æ£€æµ‹æ˜¯å¦æ”¯æŒå›¾åƒ
            supports_image = 'image' in model.get('input', [])
            
            models.append({
                'full_id': full_id,
                'provider_id': provider_id,
                'model_id': model_id,
                'name': model_name,
                'tier': tier,
                'supports_image': supports_image,
                'reasoning': model.get('reasoning', False),
                'context_window': model.get('contextWindow', 0)
            })
    
    return models


def print_current_models(models):
    """æ‰“å°å½“å‰å¯ç”¨æ¨¡å‹"""
    print("\n" + "="*60)
    print("ğŸ“¦ å½“å‰ OpenClaw å·²é…ç½®çš„æ¨¡å‹")
    print("="*60)
    
    if not models:
        print("âš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•å·²é…ç½®çš„æ¨¡å‹")
        return
    
    # æŒ‰ç­‰çº§åˆ†ç»„
    high_tier = [m for m in models if m['tier'] == 'high']
    mid_tier = [m for m in models if m['tier'] == 'mid']
    low_tier = [m for m in models if m['tier'] == 'low']
    
    def print_model_group(title, model_list):
        if model_list:
            print(f"\n{title}")
            for i, m in enumerate(model_list, 1):
                img_tag = "ğŸ–¼ï¸" if m['supports_image'] else ""
                reason_tag = "ğŸ§ " if m['reasoning'] else ""
                ctx = f"({m['context_window']//1000}k)" if m['context_window'] else ""
                print(f"  {i}. {m['name']} {img_tag}{reason_tag} {ctx}")
                print(f"     ID: {m['full_id']}")
    
    print_model_group("ğŸ”´ é«˜æ€§èƒ½æ¨¡å‹ (High Tier)", high_tier)
    print_model_group("ğŸŸ¡ ä¸­ç­‰æ¨¡å‹ (Mid Tier)", mid_tier)
    print_model_group("ğŸŸ¢ è½»é‡æ¨¡å‹ (Low Tier)", low_tier)
    
    print("\n" + "-"*60)
    print("å›¾ä¾‹: ğŸ–¼ï¸=æ”¯æŒå›¾åƒ ğŸ§ =æ”¯æŒæ¨ç†")


def suggest_model_assignment(models):
    """æ ¹æ®ç°æœ‰æ¨¡å‹å»ºè®®æ™ºèƒ½ä½“åˆ†é…"""
    print("\n" + "="*60)
    print("ğŸ¤– æ™ºèƒ½ä½“æ¨¡å‹åˆ†é…å»ºè®®")
    print("="*60)
    
    # æŒ‰ç­‰çº§åˆ†ç±»æ¨¡å‹
    high_models = [m for m in models if m['tier'] == 'high']
    mid_models = [m for m in models if m['tier'] == 'mid']
    low_models = [m for m in models if m['tier'] == 'low']
    image_models = [m for m in models if m['supports_image']]
    
    # é€‰æ‹©æ¯ä¸ªç­‰çº§çš„é¦–é€‰æ¨¡å‹
    best_high = high_models[0]['full_id'] if high_models else None
    best_mid = mid_models[0]['full_id'] if mid_models else best_high
    best_low = low_models[0]['full_id'] if low_models else best_mid
    
    # å›¾åƒæ¨¡å‹ä¼˜å…ˆé€‰æ‹©åå­—ä¸­å¸¦ "image" çš„
    image_priority = [m for m in image_models if 'image' in m['model_id'].lower()]
    best_image = image_priority[0]['full_id'] if image_priority else (image_models[0]['full_id'] if image_models else best_mid)
    
    print("\næ ¹æ®æ‚¨çš„æ¨¡å‹é…ç½®ï¼Œå»ºè®®åˆ†é…å¦‚ä¸‹ï¼š\n")
    
    assignments = {}
    for agent_id, agent_info in AGENT_ROLES.items():
        tier = agent_info['tier']
        
        if agent_id == 'designer':
            suggested = best_image
        elif tier == 'high':
            suggested = best_high
        elif tier == 'mid':
            suggested = best_mid
        else:
            suggested = best_low
        
        if suggested:
            assignments[agent_id] = suggested
            print(f"  {agent_info['emoji']} {agent_info['name']:8} â†’ {suggested}")
            print(f"     ({agent_info['desc']})")
    
    return assignments


def generate_config_patch(assignments):
    """ç”Ÿæˆé…ç½®è¡¥ä¸"""
    agents_list = []
    
    # main agent
    agents_list.append({
        "id": "main",
        "default": True,
        "workspace": "/workspace",
        "identity": {"name": "ä¸»æ™ºèƒ½ä½“", "emoji": "ğŸ¯"},
        "subagents": {"allowAgents": list(AGENT_ROLES.keys())}
    })
    
    # sub agents
    for agent_id, model_id in assignments.items():
        agent_info = AGENT_ROLES[agent_id]
        agents_list.append({
            "id": agent_id,
            "workspace": f"/workspace/agents/{agent_id}",
            "model": {"primary": model_id},
            "identity": {"name": agent_info['name'], "emoji": agent_info['emoji']}
        })
    
    return {"agents": {"list": agents_list}}


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸš€ Agent Swarm é…ç½®å‘å¯¼".center(60))
    print("="*60)
    
    # 1. åŠ è½½é…ç½®
    config, config_path = load_openclaw_config()
    if config:
        print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    else:
        print("âŒ æœªæ‰¾åˆ° OpenClaw é…ç½®æ–‡ä»¶")
        print("   è¯·ç¡®ä¿ ~/.openclaw/openclaw.json å­˜åœ¨")
        return
    
    # 2. è·å–å¯ç”¨æ¨¡å‹
    models = get_available_models(config)
    print_current_models(models)
    
    if not models:
        print("\nğŸ’¡ æ‚¨éœ€è¦å…ˆé…ç½®æ¨¡å‹æ‰èƒ½ä½¿ç”¨ Agent Swarm")
        print("   å¯é€‰çš„ä¸»æµæ¨¡å‹ï¼š")
        for model_id, info in RECOMMENDED_MODELS.items():
            print(f"   - {info['name']}: {info['desc']}")
        return
    
    # 3. å»ºè®®åˆ†é…
    assignments = suggest_model_assignment(models)
    
    # 4. è¾“å‡ºé…ç½®è¡¥ä¸
    print("\n" + "="*60)
    print("ğŸ“ ç”Ÿæˆçš„é…ç½®è¡¥ä¸ (å¯ç”¨äº gateway config.patch)")
    print("="*60)
    
    patch = generate_config_patch(assignments)
    print(json.dumps(patch, indent=2, ensure_ascii=False))
    
    # 5. ä¿å­˜åˆ°æ–‡ä»¶
    output_path = Path(__file__).parent.parent / "config-patch.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(patch, f, indent=2, ensure_ascii=False)
    print(f"\nâœ… é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
    
    print("\n" + "="*60)
    print("ä¸‹ä¸€æ­¥æ“ä½œï¼š")
    print("  1. æ£€æŸ¥ä¸Šæ–¹é…ç½®æ˜¯å¦ç¬¦åˆé¢„æœŸ")
    print("  2. å¦‚éœ€ä¿®æ”¹ï¼Œç¼–è¾‘ config-patch.json")
    print("  3. ä½¿ç”¨ gateway config.patch åº”ç”¨é…ç½®")
    print("="*60)


if __name__ == "__main__":
    main()
